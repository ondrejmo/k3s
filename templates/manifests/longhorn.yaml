---

apiVersion: helm.cattle.io/v1
kind: HelmChart
metadata:
  name: longhorn
  namespace: kube-system

spec:
  chart: https://%{KUBERNETES_API}%/static/charts/longhorn-{{ k3s_components.longhorn }}.tgz
  targetNamespace: longhorn-system
  createNamespace: true
  # https://github.com/longhorn/charts/blob/longhorn-1.7.1/charts/longhorn/values.yaml
  valuesContent: |-
    metrics:
      serviceMonitor:
        enabled: true
    networkPolicies:
      enabled: true
      type: k3s
    defaultSettings:
      backupTarget: "{{ k3s_backup }}"
      concurrentAutomaticEngineUpgradePerNodeLimit: "1"
      defaultDataLocality: best-effort
      defaultDataPath: {{ k3s_storage.longhorn }}
      defaultLonghornStaticStorageClass: longhorn
      defaultReplicaCount: "1"
      replicaAutoBalance: best-effort
      storageMinimalAvailablePercentage: "20"
      storageReservedPercentageForDefaultDisk: "10"
      storageOverProvisioningPercentage: "150"
      upgradeChecker: "false"
      logLevel: Error
      createDefaultDiskLabeledNodes: "true"
      name: create-default-disk-labeled-nodes
    persistence:
      defaultClass: false
      defaultFsType: ext4
      defaultClassReplicaCount: 1
      defaultDataLocality: best-effort
      reclaimPolicy: Retain
    # DISCLAIMER: this only works on single node clusters (https://github.com/longhorn/longhorn/issues/3816#issuecomment-1094552437)
    longhornUI:
      replicas: 1
    csi:
      attacherReplicaCount: 1
      provisionerReplicaCount: 1
      resizerReplicaCount: 1
      snapshotterReplicaCount: 1

---

apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: longhorn-ui
  namespace: longhorn-system

# DISCLAIMER: longhorn chart does not add ui networkpolicy when ingress is disabled
spec:
  podSelector:
    matchLabels:
      app: longhorn-ui
  policyTypes:
    - Ingress
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              kubernetes.io/metadata.name: kube-system
          podSelector:
            matchLabels:
              app.kubernetes.io/name: traefik
      ports:
        - port: 8000
          protocol: TCP

---

apiVersion: v1
kind: Secret
metadata:
  name: longhorn-auth
  namespace: longhorn-system

type: kubernetes.io/basic-auth
stringData:
  username: "{{ k3s_longhorn.user }}"
  password: "{{ k3s_longhorn.pass }}"

---

apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: longhorn
  namespace: longhorn-system

spec:
  commonName: {{ k3s_longhorn.host }}
  dnsNames:
    - {{ k3s_longhorn.host }}
  secretName: longhorn-certificate
  issuerRef:
    name: {{ "trusted-ca" if k3s_ca.crt != "" and k3s_ca.key != "" else "selfsigned-ca" }}
    kind: ClusterIssuer

---

apiVersion: traefik.io/v1alpha1
kind: Middleware
metadata:
  name: longhorn-auth
  namespace: longhorn-system

spec:
  basicAuth:
    secret: longhorn-auth
    realm: Longhorn

---

apiVersion: traefik.io/v1alpha1
kind: IngressRoute
metadata:
  name: longhorn
  namespace: longhorn-system
  annotations:
    external-dns.alpha.kubernetes.io/target: "{{ k3s_loadbalancer.pools[0].start }}"
    external-dns.alpha.kubernetes.io/ttl: "300"

spec:
  entryPoints:
    - websecure

  routes:
    - match: Host(`{{ k3s_longhorn.host }}`)
      kind: Rule
      services:
        - name: longhorn-frontend
          port: 80
      middlewares:
        - name: longhorn-auth

  tls:
    secretName: longhorn-certificate

{% raw %}
---

apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: longhorn
  namespace: longhorn-system

spec:
  groups:
    - name: longhorn
      rules:
      - alert: LonghornVolumeActualSpaceUsedWarning
        annotations:
          description: The actual space used by Longhorn volume {{$labels.volume}} on {{$labels.node}} is at {{$value}}% capacity for
            more than 5 minutes.
          summary: The actual used space of Longhorn volume is over 200% of the capacity.
        expr: (longhorn_volume_actual_size_bytes / longhorn_volume_capacity_bytes) * 100 > 200
        for: 5m
        labels:
          issue: The actual used space of Longhorn volume {{$labels.volume}} on {{$labels.node}} is high.
          severity: warning
      - alert: LonghornVolumeStatusCritical
        annotations:
          description: Longhorn volume {{$labels.volume}} on {{$labels.node}} is Fault for
            more than 2 minutes.
          summary: Longhorn volume {{$labels.volume}} is Fault
        expr: longhorn_volume_robustness == 3
        for: 5m
        labels:
          issue: Longhorn volume {{$labels.volume}} is Fault.
          severity: critical
      - alert: LonghornVolumeStatusWarning
        annotations:
          description: Longhorn volume {{$labels.volume}} on {{$labels.node}} is Degraded for
            more than 5 minutes.
          summary: Longhorn volume {{$labels.volume}} is Degraded
        expr: longhorn_volume_robustness == 2
        for: 5m
        labels:
          issue: Longhorn volume {{$labels.volume}} is Degraded.
          severity: warning
      - alert: LonghornNodeStorageWarning
        annotations:
          description: The used storage of node {{$labels.node}} is at {{$value}}% capacity for
            more than 5 minutes.
          summary:  The used storage of node is over 70% of the capacity.
        expr: (longhorn_node_storage_usage_bytes / longhorn_node_storage_capacity_bytes) * 100 > 70
        for: 5m
        labels:
          issue: The used storage of node {{$labels.node}} is high.
          severity: warning
      - alert: LonghornDiskStorageWarning
        annotations:
          description: The used storage of disk {{$labels.disk}} on node {{$labels.node}} is at {{$value}}% capacity for
            more than 5 minutes.
          summary:  The used storage of disk is over 100% of the capacity.
        expr: (longhorn_disk_usage_bytes / longhorn_disk_capacity_bytes) * 100 > 100
        for: 5m
        labels:
          issue: The used storage of disk {{$labels.disk}} on node {{$labels.node}} is high.
          severity: warning
      - alert: LonghornNodeDown
        annotations:
          description: There are {{$value}} Longhorn nodes which have been offline for more than 5 minutes.
          summary: Longhorn nodes is offline
        expr: longhorn_node_total - (count(longhorn_node_status{condition="ready"}==1) OR on() vector(0))
        for: 5m
        labels:
          issue: There are {{$value}} Longhorn nodes are offline
          severity: critical
      - alert: LonghornIntanceManagerCPUUsageWarning
        annotations:
          description: Longhorn instance manager {{$labels.instance_manager}} on {{$labels.node}} has CPU Usage / CPU request is {{$value}}% for
            more than 5 minutes.
          summary: Longhorn instance manager {{$labels.instance_manager}} on {{$labels.node}} has CPU Usage / CPU request is over 300%.
        expr: (longhorn_instance_manager_cpu_usage_millicpu/longhorn_instance_manager_cpu_requests_millicpu) * 100 > 300
        for: 5m
        labels:
          issue: Longhorn instance manager {{$labels.instance_manager}} on {{$labels.node}} consumes 3 times the CPU request.
          severity: warning
      - alert: LonghornNodeCPUUsageWarning
        annotations:
          description: Longhorn node {{$labels.node}} has CPU Usage / CPU capacity is {{$value}}% for
            more than 5 minutes.
          summary: Longhorn node {{$labels.node}} experiences high CPU pressure for more than 5m.
        expr: (longhorn_node_cpu_usage_millicpu / longhorn_node_cpu_capacity_millicpu) * 100 > 90
        for: 5m
        labels:
          issue: Longhorn node {{$labels.node}} experiences high CPU pressure.
          severity: warning

{% endraw %}
---

apiVersion: longhorn.io/v1beta2
kind: RecurringJob
metadata:
  name: default-backup
  namespace: longhorn-system

spec:
  retain: 30
  concurrency: 1
  name: default-backup
  labels: {}
  task: backup
  cron: 0 7,19 * * *
  groups:
    - default

---

kind: VolumeSnapshotClass
apiVersion: snapshot.storage.k8s.io/v1
metadata:
  name: longhorn

driver: driver.longhorn.io
deletionPolicy: Delete
